Android音视频的编解码

android_atomic_inc()原子操作函数
android_atomic_add()
const_cast<RefBase*>
Android中提出了一套类似Java垃圾回收机制的智能指针，采用强指针sp（Strong Pointer）和弱指针wp（Weak Pointer）对目标对象进行应用，实现对象的自动回收。
对象可以分为全局对象、局部对象、静态全局对象和静态局部对象。
Android设计了强引用sp和弱引用wp，故实际对象的释放，可分为强引用控制和弱引用控制。所谓强引用控制，指的是强引用数mStrong为0时，释放实际对象；弱引用控制，则指的是弱引用数mWeak为0时，才释放实际对象。


// encoder
result = avcodec_send_frame(audioAVCodecContext, frame);
result = avcodec_receive_packet(audioAVCodecContext, avPacket);

// decoder
result = avcodec_send_packet(audioAVCodecContext, avPacket);
result = avcodec_receive_frame(audioAVCodecContext, decoded_frame);


cd x264
CC=cl ./configure --enable-static --enable-shared --enable-pic


 ./configure --toolchain=msvc --enable-yasm --enable-asm --enable-gpl --enable-libx264 --extra-cflags=-I/usr/local/include --extra-ldflags=-LIBPATH:/usr/local/lib



 ./configure --prefix=/root/mydev/tools/ffmpeg --enable-libmp3lame --enable-static --enable-shared --enable-x86asm --enable-asm --enable-gpl --enable-libx264


Stream #0.0[0x1e0]: Video: mpeg2video, yuv420p, 704x576 [PAR 12:11 DAR 4:3], 9578 kb/s, 25 tbr, 90k tbn, 50 tbc
25  tbr 代表帧率
90k tbn 代表文件层的时间精度,即1S=1200k,和duration相关
50  tbc 代表视频层的时间精度,即1S=50,和strem->duration和时间戳相关

在AndroidAPI <= 20（Android5.0之前的版本）中Google支持的CameraPreview Callback的YUV常用格式有两种：一个是NV21，一个是YV12。如果我们需要对Camera采集的图像进行编码等，必须要对其进一步处理，比如格式转换、旋转等操作，否则会出现一些花屏、叠影等问题。	


采样率：每秒钟记录多少个采样点；
在H264协议里定义了三种帧，完整编码的帧叫I帧，参考之前的I帧生成的只包含差异部分编码的帧叫P帧，还有一种参考前后的帧编码的帧叫B帧。
H264采用的核心算法是帧内压缩和帧间压缩，帧内压缩是生成I帧的算法，帧间压缩是生成B帧和P帧的算法。

ffmpeg提供了av_rescale_q_rnd函数进行转换。
av_rescale_q_rnd(int64_t a, int64_t b, int64_t c, enum AVRounding rnd)
此函数主要用于对于不同时间戳的转换。具体来说是将原来以 "时间基b" 表示的 数值a 转换成以 "时间基c" 来表示的新值。AVRounding表示取整的策略

ffmpeg -i /media/1.WAV -acodec libmp3lame /media/1.MP3
ffmpeg -i apple.mp4 -f mp3 -vn apple.mp3
参数解释：
-i 表示input，即输入文件
-f 表示format，即输出格式
-vn表示vedio not，即输出不包含视频
对比源视频文件和提取得到的音频文件大小，可以看到源视频文件为约23M，而提取出来的音频文件大小为3M。

FFmpeg还提供了很多有用的工具可以查看和处理音视频文件，如：
查看视频文件的音视频编解码格式，视频时长，比特率等，如下：
dennis@ubuntu:~$ ffmpeg -i apple.mp4

ffmpeg -i test.mp4 -vcodec libx264 -b:v 1200k -r 25 -acodec mp3 -ab 128k -ar 44100 output.mp4

ffmpeg -codecs
ffmpeg -codecs | grep aac

[whb@jcwkyl introduction_to_algorithm]$ ffmpeg -i Lecture_1.flv -f mp2 -vn Lecture_1.mp3
这条命令中，-i表示input file，-f表示输出格式，-vn表示“vedio not"，即禁止视频输出，最后转换后的文件是Lecture_1.mp3。
转换完成后，使用file命令查看Lecture_1.mp3的文件格式：
[whb@jcwkyl introduction_to_algorithm]$ file Lecture_1.mp3
Lecture_1.mp3: MPEG ADTS, layer II, v2,  64 kBits, 22.05 kHz, Stereo
转换前后文件大小对比：
[whb@jcwkyl introduction_to_algorithm]$ du -hs Lecture_1.*
153M    Lecture_1.flv
37M     Lecture_1.mp3
使用播放器播放Lecture_1.mp3，完全正常。



avCodec = avcodec_find_encoder_by_name("libfdk_aac");

常用的立体声有2个通道，环绕立体声3个通道。
声道数目 立体声（stero）单声道（mono）

采样率  单位时间内对音频ad芯片的采样次数，常见的音频采样率有。
 0: 96000 Hz
 1: 88200 Hz
 2: 64000 Hz
 3: 48000 Hz
 4: 44100 Hz
 5: 32000 Hz
 6: 24000 Hz
 7: 22050 Hz
 8: 16000 Hz
 9: 12000 Hz
10: 11025 Hz
11: 8000 Hz
12: 7350 Hz
13: Reserved
14: Reserved
15: frequency is written explicitly
左边是adts头里面对应的采样率编码值，右边是对应的采样率值。
单采样bit数目  单个采样的bit位数，16／8 bit。

ffmpeg中的一些参数：
   out_sample_format 音频采样格式
   sample_rate 采样率值（非编码值）
   in_channel_layout 解码后的PCM数据layout格式，左左左右右右   左右左右左右
   nb_samples  一帧音频中的采样个数，用于计算一帧数据大小

注意ffmpeg中的两个结构，AVPacket(编码的音视频帧),AVFrame(解码后的音视频数据)
AVPacket packet = {0};
packet.data =(uint8_t*)buf;
    packet.size = len;
AVFrame *decode_frame = avcodec_alloc_frame();
if(decode_frame == NULL)
{
return -1;
}
//前面已经初始化过解码器
int audio4_decode_len = avcodec_decode_audio4(av_codec_ctx_,decode_frame,got_frame,&packet);//解码
if(audio4_decode_len < 0||*got_frame != 1)
{
return -1;
}
AVSampleFormat out_sample_format = AV_SAMPLE_FMT_S16;
struct SwrContext *audio_convert_ctx;
        audio_convert_ctx = swr_alloc();
unsigned long long in_channel_layout = av_get_default_channel_layout(av_codec_ctx_->channels);
                    audio_convert_ctx = swr_alloc_set_opts(audio_convert_ctx,in_channel_layout,out_sample_format,av_codec_ctx_->sample_rate,
                                    in_channel_layout,av_codec_ctx_->sample_fmt,av_codec_ctx_->sample_rate,0,NULL);
swr_init(audio_convert_ctx);                   
    int nb_samples = swr_convert(audio_convert_ctx,//重采样，返回的值是新的采样率的一帧中的采样个数，可以根据声道和采样bit数目计算一帧数据大小
                       (uint8_t **)&outbuf,
                       AVCODEC_MAX_AUDIO_FRAME_SIZE,
                       (const uint8_t **)decode_frame->data,
                       decode_frame->nb_samples);
outlen = av_samples_get_buffer_size(NULL,av_codec_ctx_->channels ,nb_samples,out_sample_format, 1);//计算出重采样后一帧pcm数据的大小
sample_rate = av_codec_ctx_->sample_rate;
channels = av_codec_ctx_->channels;
avcodec_free_frame(&decode_frame);
