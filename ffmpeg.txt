libswscale图像格式转换与放大缩小
简单的初始化方法
（1）       sws_getContext()：使用参数初始化SwsContext结构体。
（2）       sws_scale()：转换一帧图像。
（3）       sws_freeContext()：释放SwsContext结构体。
其中sws_getContext()也可以用sws_getCachedContext()取代。
更灵活的初始化方法，可以配置更多的参数：
（1）       sws_alloc_context()：为SwsContext结构体分配内存。
（2）       av_opt_set_XXX()：通过av_opt_set_int()，av_opt_set()…等一系列方法设置SwsContext结构体的值。在这里需要注意，SwsContext结构体的定义看不到，所以不能对其中的成员变量直接进行赋值，必须通过av_opt_set()这个API才能对其进行赋值。
（3）       sws_init_context()：初始化SwsContext结构体。
这种复杂的方法可以配置一些sws_getContext()配置不了的参数。
比如说设置图像的YUV像素的取值范围是
JPEG标准（Y、U、V取值范围都是0-255）
还是MPEG标准（Y取值范围是16-235，U、V的取值范围是16-240）。
可以通过使用av_opt_set()来设置“src_range”和“dst_range”输入和输出的YUV的取值范围。如果“dst_range”字段设置为“1”的话，则代表输出的YUV的取值范围遵循“jpeg”标准；如果“dst_range”字段设置为“0”的话，则代表输出的YUV的取值范围遵循“mpeg”标准。
如:
SwsContext *img_convert_ctx = sws_alloc_context();  
av_opt_set_int(img_convert_ctx,"sws_flags",SWS_BICUBIC|SWS_PRINT_INFO,0);  
av_opt_set_int(img_convert_ctx,"srcw",src_w,0);  
av_opt_set_int(img_convert_ctx,"srch",src_h,0);  
av_opt_set_int(img_convert_ctx,"src_format",src_pixfmt,0);  
av_opt_set_int(img_convert_ctx,"src_range",1,0);  
av_opt_set_int(img_convert_ctx,"dstw",dst_w,0);  
av_opt_set_int(img_convert_ctx,"dsth",dst_h,0);  
av_opt_set_int(img_convert_ctx,"dst_format",dst_pixfmt,0);  
av_opt_set_int(img_convert_ctx,"dst_range",1,0);  
sws_init_context(img_convert_ctx,NULL,NULL);  
算法性能测试：
缩小：
SWS_POINT   每秒钟可缩放约427次 效率之高，让我震撼，但效果却不差。
SWS_FAST_BILINEAR   228次
放大
SWS_POINT  112次，边缘有明显锯齿
SWS_FAST_BILINEAR 103次，效果不错
建议:
在不明确是放大还是缩小时，直接使用SWS_FAST_BILINEAR算法即可。
如果明确是要缩小并显示，建议使用Point算法。
FFmpeg使用不同sws_scale()缩放算法的命令示例
	ffmpeg -s 480x272 -pix_fmt yuv420p -i src01_480x272.yuv -s 1280x720 -sws_flags bilinear -pix_fmt yuv420p src01_bilinear_1280x720.yuv  
	ffmpeg -s 480x272 -pix_fmt yuv420p -i src01_480x272.yuv -s 1280x720 -sws_flags bicubic -pix_fmt yuv420p src01_bicubic_1280x720.yuv  
	ffmpeg -s 480x272 -pix_fmt yuv420p -i src01_480x272.yuv -s 1280x720 -sws_flags neighbor -pix_fmt yuv420p src01_neighbor_1280x720.yuv  

像素格式
（1）       所有的像素格式的名称都是以“AV_PIX_FMT_”开头
（2）       像素格式名称后面有“P”的，代表是planar格式，否则就是packed格式。Planar格式不同的分量分别存储在不同的数组中，例如AV_PIX_FMT_YUV420P存储方式如下：
data[0]: Y1, Y2, Y3, Y4, Y5, Y6, Y7, Y8……
data[1]: U1, U2, U3, U4……
data[2]: V1, V2, V3, V4……
Packed格式的数据都存储在同一个数组中，例如AV_PIX_FMT_RGB24存储方式如下：
data[0]: R1, G1, B1, R2, G2, B2, R3, G3, B3, R4, G4, B4……
（3）       像素格式名称后面有“BE”的，代表是Big Endian格式；名称后面有“LE”的，代表是Little Endian格式。

图像拉伸
FFmpeg支持多种像素拉伸的方式。这些方式的定义位于libswscale\swscale.h中，如下所示。
#define SWS_FAST_BILINEAR     1
#define SWS_BILINEAR          2
#define SWS_BICUBIC           4
#define SWS_X                 8
#define SWS_POINT          0x10
#define SWS_AREA           0x20
#define SWS_BICUBLIN       0x40
#define SWS_GAUSS          0x80
#define SWS_SINC          0x100
#define SWS_LANCZOS       0x200
#define SWS_SPLINE        0x400
其中SWS_BICUBIC性能比较好;
SWS_FAST_BILINEAR在性能和速度之间有一个比较好的平衡;
而SWS_POINT的效果比较差.

YUV像素取值范围
FFmpeg中可以通过使用av_opt_set()设置“src_range”和“dst_range”来设置输入和输出的YUV的取值范围。如果“dst_range”字段设置为“1”的话，则代表输出的YUV的取值范围遵循“jpeg”标准；如果“dst_range”字段设置为“0”的话，则代表输出的YUV的取值范围遵循“mpeg”标准。
与RGB每个像素点的每个分量取值范围为0-255不同（每个分量占8bit），YUV取值范围有两种：
（1）       以Rec.601为代表（还包括BT.709 / BT.2020）的广播电视标准中，
					Y的取值范围是16-235，U、V的取值范围是16-240。FFmpeg中称之为“mpeg”范围。
（2）       以JPEG为代表的标准中，Y、U、V的取值范围都是0-255。FFmpeg中称之为“jpeg” 范围。
实际中最常见的是第1种取值范围的YUV（可以自己观察一下YUV的数据，会发现其中亮度分量没有取值为0、255这样的数值）。